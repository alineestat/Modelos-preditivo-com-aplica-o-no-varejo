# -*- coding: utf-8 -*-
"""Modelagem DeepAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N0AbNsXn0H_mdmOmIRDNVVsONxPQTgCM

### Bibliografias utilizadas 

* https://kekayan.medium.com/forecasting-with-deepar-for-busy-people-ed67f9d9a00d

* https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html
"""

! pip install mxnet gluonts ujson

pip install gluonts

!pip install mxnet-cu101 gluonts ujson

pip install gluonts[mxnet,pro]

!pip install "gluonts[torch,pro]"

!sudo apt install libquadmath0
!sudo apt install libnccl2=2.8.4-1+cuda11.2 --allow-downgrades -y
!pip install mxnet-cu112
!pip install --upgrade gluont

from gluonts.dataset.common import ListDataset
from gluonts.model.deepar import DeepAREstimator
from gluonts.mx.trainer import Trainer
from gluonts.dataset.util import to_pandas
from gluonts.evaluation import Evaluator
from gluonts.evaluation.backtest import make_evaluation_predictions

from gluonts.mx.trainer import Trainer
from gluonts.model.predictor import Predictor

#@markdown Carregando pacotes

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import datetime 

from gluonts.dataset.common import ListDataset
from gluonts.dataset.util import to_pandas

from gluonts.model.deepar import DeepAREstimator
from gluonts.mx.distribution import ZeroInflatedNegativeBinomialOutput, StudentTOutput #likelihood
from gluonts.mx.trainer.learning_rate_scheduler import LearningRateReduction
from gluonts.mx.trainer import Trainer
from gluonts.mx.trainer.model_averaging import ModelAveraging, SelectNBestSoftmax, SelectNBestMean
from gluonts.evaluation import Evaluator
from gluonts.evaluation.backtest import make_evaluation_predictions

"""## <center> Modelagem com DeepAR <center>"""

#@markdown ####Leitura e tratamento base de dados
dados = pd.read_excel("/content/drive/MyDrive/Modelos Preditivos/Modelagem Matriz/Unidade Matriz/DadosLojaCosmeticos.xlsx")
colunas = ['dia', 'mês', 'ano', 'Dia_da_semana', 'Num_Semana_mes', 'feriados', 'pagamento', 'Vale']
for i in range(len(colunas)):
  dados[colunas[i]] = dados[colunas[i]].astype(int)
dados = dados[dados['Data'] < '2021-04-01']

#@markdown Preparação Base de Dados
dados = dados[dados['Data'] > '2018-12-31']	
df = dados[['Data', 'Vendas']].set_index('Data').sort_index()

#@markdown Base Treinamento

#@markdown Os dados de treinamento precisam conter apenas os dados de treinamento


training_data = ListDataset(
    [{"start": df.index[0], "target": df.Vendas[:"2020-06-30 T00:00:00.000000"], }], ## Na target informar até período máximo contido na base de dados
    freq = "D"
)


entry = next(iter(training_data))
train_series = to_pandas(entry)
train_series.plot()
plt.grid(which="both")
plt.legend(["train series"], loc="upper left")
# plt.title(entry['item_id'])
plt.show()

#@markdown Base Teste

#@markdown Dados de teste precisam conter os dados de treinamento e teste.


test_data = ListDataset(
    [{"start": df.index[0], "target": df.Vendas[:"2021-04-01T00:00:00.000000"]}],
    freq = "D"
)

entry = next(iter(test_data))
test_series = to_pandas(entry)
test_series.plot()
plt.axvline(df.index[-24], color='r') # end of train dataset
plt.grid(which="both")
plt.legend(["test series", "end of train series"], loc="upper left")
# plt.title(entry['item_id'])
plt.show()

test_data

#@markdown Modelagem Base Treinamento

callbacks = [
    LearningRateReduction(objective="min",
                          patience=10,
                          base_lr=1e-3,
                          decay_factor=0.5,
                          ),
    ModelAveraging(avg_strategy=SelectNBestMean(num_models=2))
]


estimator = DeepAREstimator(
    freq="D",
    prediction_length= 273,
    context_length= 547, # qtd valores base treino
    num_layers = 2,
    num_cells = 40,
    distr_output=StudentTOutput(),
    dropout_rate=0.01,
    trainer=Trainer(#ctx = mx.context.gpu(),
                    epochs=300,
                    callbacks=callbacks))

predictor = estimator.train(training_data)

#@markdown Agora podemos usar o preditor para prever nossos dados de teste.


forecast_it, ts_it = make_evaluation_predictions(
    dataset=test_data,  # test dataset
    predictor=predictor,  # predictor
    num_samples=100,  # number of sample paths we want for evaluation
)

forecasts = list(forecast_it)
tss = list(ts_it)
ts_entry = tss[0]
forecast_entry = forecasts[0]
def plot_prob_forecasts(ts_entry, forecast_entry):
    plot_length = 150
    prediction_intervals = (50.0, 90.0)
    legend = ["observations", "median prediction"] + [f"{k}% prediction interval" for k in prediction_intervals][::-1]

    fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series
    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')
    plt.grid(which="both")
    plt.legend(legend, loc="upper left")
    plt.show()

def plot_prob_forecasts(ts_entry, forecast_entry):
    plot_length = 273
    prediction_intervals = (50.0, 90.0)
    legend = ["observations", "median prediction"] + [f"{k}% prediction interval" for k in prediction_intervals][::-1]

    fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series
    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')
    plt.fill_between(
                 color='k', alpha=.00)
    plt.grid(which="both")
    plt.legend(legend, loc="upper left")
    plt.show()

"""A previsão probabilística é apresentada no gráficos a seguir. O modelo fornece uma estimativa de quão confiável é o modelo e permite que decisões posteriores com base nessas previsões levem em consideração essa incerteza"""

def plot_prob_forecasts(ts_entry, forecast_entry):
    plot_length = 273
    prediction_intervals = (80.0, 90.0)
    legend = ["observations", "median prediction"] + [f"{k}% prediction interval" for k in prediction_intervals][::-1]

    fig, ax = plt.subplots(1, 1, figsize=(20, 7))
    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series
    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')
    plt.grid(which="both")
    plt.legend(legend, loc="upper left")
    plt.show()




plot_prob_forecasts(ts_entry, forecast_entry)

"""Verificando as métricas como MSE, MASE, MAPE simétrico, RMSE usando Evaluatorfrom gluonTs."""

evaluator = Evaluator()
agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_data))

import json
print(json.dumps(agg_metrics, indent=4))